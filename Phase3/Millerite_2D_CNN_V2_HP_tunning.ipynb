{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Millerite_2D_CNN_V2_HP_tunning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHqCR7gODyU448lAIPCn80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk7exe/millerite/blob/master/Phase3/Millerite_2D_CNN_V2_HP_tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k6oNh2CbP6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "# %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ELfkhUxbcya",
        "colab_type": "text"
      },
      "source": [
        "Downloading dataset files:\n",
        "\n",
        "Local run: When run locally dataset files can be accessed from the project folder.\n",
        "Colab run: Datasets should be downloaded from github (This downloads data sets in the notebook's path). We also mount google drive to load and save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlm8HecZbfRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local = False\n",
        "if local:\n",
        "    root_path = '/home/mk/Uni/GitHub Projects/millerite/Phase2/Steinhadt/datasets'\n",
        "    drive_path = '/home/mk/GoogleDrive/Colab Notebooks'\n",
        "    \n",
        "else:\n",
        "    ! wget -nv https://github.com/mk7exe/millerite/raw/master/Phase2/Steinhadt/datasets/data.zip -O data.zip\n",
        "    root_path = './datasets'\n",
        "    ! unzip -o data.zip\n",
        "    # Mountng Google Drive\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/gdrive')\n",
        "    # drive_path = 'gdrive/My Drive/Colab Notebooks'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej3vFCwPbkHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    dataset = h5py.File(root_path + '/data_2D.h5', \"r\")\n",
        "    xtrain = np.array(dataset[\"xtrain\"][:])\n",
        "    ytrain = np.array(dataset[\"ytrain\"][:]) \n",
        "    xdev = np.array(dataset[\"xdev\"][:])\n",
        "    ydev = np.array(dataset[\"ydev\"][:])\n",
        "    xtest = np.array(dataset[\"xtest\"][:])\n",
        "    ytest = np.array(dataset[\"ytest\"][:])\n",
        "    \n",
        "    surf_dataset = h5py.File(root_path + '/surface_2D.h5', \"r\")\n",
        "    xsurf = np.array(surf_dataset[\"x\"][:])\n",
        "    ysurf = np.array(surf_dataset[\"y\"][:])\n",
        "\n",
        "    return xtrain, ytrain, xdev, ydev, xtest, ytest, xsurf, ysurf\n",
        "\n",
        "xtrain, ytrain, xdev, ydev, xtest, ytest, xsurf, ysurf = load_data()\n",
        "\n",
        "print(xtrain.shape, ytrain.shape, xdev.shape, ydev.shape, xtest.shape, \n",
        "      ytest.shape, xsurf.shape, ysurf.shape)\n",
        "print(np.max(xtrain), np.max(xdev), np.max(xtest), np.max(xsurf))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJJFzUh4blED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = [id for id, elm in enumerate(ytrain) if elm < 2]\n",
        "ytrain = ytrain[ids]\n",
        "xtrain = xtrain[ids,:]\n",
        "print(xtrain.shape, ytrain.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gg8EndhbntZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([512]))\n",
        "HP_DROPOUT1 = hp.HParam('dropout1', hp.Discrete([0.0, 0.1, 0.2]))\n",
        "HP_DROPOUT2 = hp.HParam('dropout2', hp.Discrete([0.0, 0.1, 0.2]))\n",
        "HP_alpha = hp.HParam('alpha', hp.Discrete([0.0001, 0.001]))\n",
        "HP_lambdaL2 = hp.HParam('lambdaL2', hp.Discrete([0.0, 0.001, 0.01]))\n",
        "# HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['tanh', 'sigmoid', 'relu']))\n",
        "# HP_OUT_ACTIVATION = hp.HParam('output', hp.Discrete(['linear']))\n",
        "\n",
        "METRIC_ACCURACY = 'root_mean_squared_error'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT1, HP_DROPOUT2, HP_alpha, HP_lambdaL2],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='RMSE')]\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91dUasZMclSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_model(hparams, epochs):\n",
        "  lambdaL2 = hparams[HP_lambdaL2]\n",
        "  dropout1 = hparams[HP_DROPOUT1]\n",
        "  dropout2 = hparams[HP_DROPOUT2]\n",
        "  learning_rate = hparams[HP_alpha]  \n",
        "  num_units = hparams[HP_NUM_UNITS]\n",
        "  activation = 'relu'\n",
        "  out_activation = 'linear'\n",
        "\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.Input(shape=(100, 100, 1)))\n",
        "  model.add(keras.layers.Conv2D(filters=16, kernel_size=(9, 9), \n",
        "                                activation=activation))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "  model.add(keras.layers.Conv2D(filters=32, kernel_size=(5, 5),\n",
        "                                activation=activation))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "\n",
        "  model.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                                activation=activation))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "\n",
        "  model.add(keras.layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
        "                                activation=activation))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dropout(dropout1))\n",
        "  # model.add(keras.layers.GlobalMaxPooling2D())\n",
        "  model.add(keras.layers.Dense(num_units, kernel_regularizer=\n",
        "                                keras.regularizers.l2(lambdaL2)))\n",
        "  model.add(keras.layers.Dropout(dropout2))\n",
        "  model.add(keras.layers.Dense(num_units/4, kernel_regularizer=\n",
        "                                keras.regularizers.l2(lambdaL2)))\n",
        "  model.add(keras.layers.Dropout(dropout2))\n",
        "  model.add(keras.layers.Dense(1, activation=out_activation))\n",
        "\n",
        "  adam = keras.optimizers.Adam(learning_rate=learning_rate,\n",
        "                               beta_1=0.9, beta_2=0.999) \n",
        "  model.compile(optimizer=adam, \n",
        "                loss=keras.losses.mean_squared_error, \n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
        "\n",
        "  _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "  _, accuracy = model.evaluate(x_dev, y_dev)\n",
        "  return train_accuracy, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORvyw5tIcoKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(run_dir, hparams, epochs):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    train_accuracy, accuracy = train_test_model(hparams, epochs)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opGLnPcPcr3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./logs/*\n",
        "%tensorboard --logdir ./logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiQCoLzycu7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout1 in HP_DROPOUT1.domain.values:\n",
        "    for dropout2 in HP_DROPOUT2.domain.values:\n",
        "      for alpha in HP_alpha.domain.values:\n",
        "        for lambdaL2 in HP_lambdaL2.domain.values:\n",
        "          hparams = {\n",
        "              HP_NUM_UNITS: num_units,\n",
        "              HP_DROPOUT1: dropout1,\n",
        "              HP_DROPOUT2: dropout1,\n",
        "              HP_alpha: alpha,\n",
        "              HP_lambdaL2: lambdaL2,\n",
        "          }\n",
        "          run_name = \"run-%d\" % session_num\n",
        "          print('--- Starting trial: %s' % run_name)\n",
        "          print({h.name: hparams[h] for h in hparams})\n",
        "          run('logs/fit/' + run_name, hparams, epochs)\n",
        "          session_num += 1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}